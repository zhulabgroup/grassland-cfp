# Climate niche estimation

Setup and load packages.

```{r, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, eval = TRUE, cache = TRUE)
```

```{r}
library(tidyverse)
library(sf)
library(patchwork)
```

## Get occurrence data

The first question is what the geographic extent that we search for occurrence records. Joise used the state of California for convenience, but it seems to make more sense using an ecological, not administrative, boundary. We thought about using NEON domains. After much discussion, we decided to use the [biodiversity hotspots](https://www.cepf.net/our-work/biodiversity-hotspots). The most relevant one is California Floristic Province (CFP). Study sites seem to distribute nicely across CFP. 

```{r}
site_sf <- read_rds("data/community/site-info.rds")
site_sf %>%
  as_tibble() %>% # drop geometry
  knitr::kable()
```

Make a map overlaying sites with CFP and admin boundaries from [Natural Earth](https://www.naturalearthdata.com/). 

```{r}
cfp_sf <- st_read("data/occurrence/hotspots/hotspots_2016_1.shp") %>%
  filter(
    NAME == "California Floristic Province",
    Type == "hotspot area"
  )

(ggplot() +
  geom_sf(
    data = rnaturalearth::ne_states(
      country = c("Mexico", "United States of America"),
      returnclass = "sf"
    ),
    fill = NA,
    color = alpha("black", .1)
  ) +
  geom_sf(data = cfp_sf, fill = "white", alpha = .5) +
  geom_sf(data = site_sf, color = "red", aes(text = name)) +
  labs(x = "Longitude", y = "Latitude") +
  coord_sf(xlim = c(-125, -115), ylim = c(28, 44))
) %>%
  plotly::ggplotly(tooltip = "text")
```

Load all the species from community data.

```{r}
spp_tbl <- read_rds("data/community/all-experimental-data.rds") %>%
  select(species) %>%
  bind_rows(
    read_rds("data/community/all-experimental-data.rds") %>%
      select(species)
  ) %>%
  distinct(species) %>%
  arrange(species)
```

### GBIF

Extract occurrence data from GBIF, using the species list. The query output is an object of class `occdat`. Convert it to nested data, then unnest the data. Save GBIF occurrence data to a file.

```{r, eval=FALSE}
# ~ 13 min to run
library(foreach)
library(doSNOW)
num_cores <- 22 # socs-stats has 44 cores
cl <- makeCluster(num_cores)
registerDoSNOW(cl)
gbif_box_ls <-
  foreach(
    i = 1:length(spp_tbl$species),
    .packages = c("spocc", "sf", "tidyverse")
  ) %dopar% {
    sp <- spp_tbl$species[i]
    res <- occ(
      query = sp, from = "gbif", has_coords = TRUE, limit = 1e6,
      geometry = st_bbox(cfp_sf),
      gbifopts = list(
        # occ_options(from = "gbif", where = "console")
        hasGeospatialIssue = FALSE
      )
    )
    print(i)
    tibble(queryName = sp, gbif = res$gbif$data) %>%
      unnest(cols = c(gbif))
  }
stopCluster(cl)

gbif_box_tbl <- bind_rows(gbif_box_ls) # collapse from list to tibble

gbif_cfp_tbl <- gbif_box_tbl %>%
  select(key, longitude, latitude) %>%
  st_as_sf(coords = c("longitude", "latitude"), crs = 4326) %>%
  st_intersection(cfp_sf) %>% # find GBIF and CFP intersection
  as_tibble() %>% # drop geometry
  select(key) %>% # use key to join (fast)
  right_join(gbif_box_tbl, ., by = "key")

write_rds(gbif_cfp_tbl, "data/occurrence/gbif/gbif-cfp-2022-05-04.rds")

rm(list = c("cl", "num_cores", "gbif_box_ls", "gbif_box_tbl", "gbif_cfp_tbl"))
```

Note that GBIF depends on download dates. Here's a test.

```{r, eval=FALSE}
# tested on 20220424

##### Getting today's occ data
sp <- "Achillea millefolium"
res <- occ(
  query = sp, from = "gbif", has_coords = TRUE, limit = 1e6,
  geometry = st_bbox(cfp_sf),
  gbifopts = list(
    hasGeospatialIssue = FALSE
  )
)
sp_df <- tibble(queryName = sp, gbif = res$gbif$data) %>%
  unnest(cols = c(gbif))

gbif_occ_box_df <- sp_df
occ_sf_box <- st_as_sf(
  x = gbif_occ_box_df %>% dplyr::select(key, longitude, latitude),
  coords = c("longitude", "latitude"),
  crs = 4326
)
occ_sf <- st_intersection(occ_sf_box, cfp_sf)
gbif_occ_df <- gbif_occ_box_df %>%
  right_join(as_tibble(occ_sf) %>% dplyr::select(key), by = "key")

gbif_occ_df_today <- gbif_occ_df
write_rds(gbif_occ_df_today, "data/occurrence/gbif/gbif-cfp-2022-04-27-test.rds")
##### Comparing with previous data

# Comparing with 0323 data
gbif_occ_df_0323 <- read_rds("data/occurrence/gbif/gbif-cfp-2022-03-23.rds")
# some record keys seem to be deleted, some added
# in 0323 but not in today
diff1 <- anti_join(gbif_occ_df_0323 %>% filter(queryName == sp), gbif_occ_df_today, by = c("queryName", "key"))
diff1 %>% nrow()
diff1 %>%
  pull(lastCrawled) %>%
  as.Date() %>%
  unique() %>%
  sort()
# in today but not in 0323
diff2 <- anti_join(gbif_occ_df_today, gbif_occ_df_0323 %>% filter(queryName == sp), by = c("queryName", "key"))
diff2 %>% nrow()
diff2 %>%
  pull(lastCrawled) %>%
  as.Date() %>%
  unique() %>%
  sort()

# Comparing with 0418 data
gbif_occ_df_0418 <- read_rds("data/occurrence/gbif/gbif-cfp-2022-04-18.rds")
# no difference in record keys but some records have been re-crawled judging from the crawId
# in 0418 but not in today
diff1 <- anti_join(gbif_occ_df_0418 %>% filter(queryName == sp), gbif_occ_df_today, by = c("queryName", "key", "crawlId"))
diff1 %>% nrow()
diff1 %>%
  pull(lastCrawled) %>%
  as.Date() %>%
  unique() %>%
  sort()
# in today but not in 0418
diff2 <- anti_join(gbif_occ_df_today, gbif_occ_df_0418 %>% filter(queryName == sp), by = c("queryName", "key", "crawlId"))
diff2 %>% nrow()
diff2 %>%
  pull(lastCrawled) %>%
  as.Date() %>%
  unique() %>%
  sort()

# 0425 data do not have this species for some reason?
```

### iNaturalist

Not directly querying the data separately because:

1. Hard limit of 10,000 records
2. Very slow
3. May be blocked if running too many queries in a minute

```{r, eval=FALSE}
res <- occ(
  query = gbif_occ_df_today, from = "inat", has_coords = TRUE, limit = 10000,
  geometry = st_bbox(cfp_sf)
)
```

4. A recommended way to get a lot of data at once is to use the dataset of research grade observations submitted weekly to GBIF https://www.gbif.org/dataset/50c9509d-22c7-4a22-a47d-8c48425ef4a7

```{r, eval=FALSE}
read_rds("data/occurrence/gbif/gbif-cfp-2022-05-04.rds") %>%
  filter(datasetName == "iNaturalist research-grade observations") %>%
  select(species = queryName, longitude, latitude, key) %>%
  write_rds("data/occurrence/inat/inat-cfp-2022-05-04.rds")
```

### BIEN

Retrieve all BIEN data then select those within CFP. Note, the code can't run because of BIEN server error, as of 5/2/2022.

```{r, eval=FALSE}
library(foreach)
library(doSNOW)
num_cores <- 22 # socs-stats has 44 cores
cl <- makeCluster(num_cores)
registerDoSNOW(cl)
bien_df_list <-
  foreach(
    i = 1:length(spp_tbl$species),
    .packages = c("BIEN", "tidyverse")
  ) %dopar% {
    sp <- spp_tbl$species[i]
    res <- BIEN_occurrence_species(species = sp)
    print(i)
    tibble(queryName = sp, res) %>%
      mutate(date_collected = as.Date(date_collected))
  }
bien_all_df <- bind_rows(bien_df_list) %>%
  mutate(key = row_number()) %>%
  drop_na(latitude, longitude)
stopCluster(cl)

bien_all_sf <- st_as_sf(
  x = bien_all_df %>% dplyr::select(key, longitude, latitude),
  coords = c("longitude", "latitude"),
  crs = 4326
)
bien_cfp_sf <- st_intersection(bien_all_sf, cfp_sf)
bien_cfp_df <- bien_all_df %>%
  right_join(as_tibble(bien_cfp_sf) %>% dplyr::select(key), by = "key")
write_rds(bien_all_df, "data/occurrence/bien/bien-all-2022-04-27.rds")
write_rds(bien_cfp_df, "data/occurrence/bien/bien-cfp-2022-04-27.rds")
```

### eJepson (CCH)

eJepson might be more accurate compared to iNat and GBIF.

Download full dataset at https://www.cch2.org/portal/collections/harvestparams.php
(Searching within the bounding box of 55N-10N, 130W-50W.)

Keep records with species of interest and within CFP.

```{r, eval=FALSE}
cch_all_tbl <- read_csv("data/occurrence/cch/occurrences.csv") %>%
  filter(scientificName %in% spp_tbl$species) %>%
  drop_na(decimalLongitude, decimalLatitude) %>%
  select(
    queryName = scientificName,
    longitude = decimalLongitude,
    latitude = decimalLatitude,
    key = id
  )

cch_cfp_tbl <- cch_all_tbl %>%
  st_as_sf(coords = c("longitude", "latitude"), crs = 4326) %>%
  st_intersection(cfp_sf) %>% # find CCH and CFP intersection
  as_tibble() %>% # drop geometry
  select(key) %>% # use key to join (fast)
  right_join(cch_all_tbl, ., by = "key")

write_rds(cch_all_tbl, "data/occurrence/cch/cch-all-2022-05-02.rds")
write_rds(cch_cfp_tbl, "data/occurrence/cch/cch-cfp-2022-05-02.rds")

rm(list = c("cch_all_tbl", "cch_cfp_tbl"))
```

### Compare occurrence data sets

Compare the above data sets, in alphabetical order, BIEN, CCH, GBIF, iNat.

```{r}
bien_tbl <- read_rds("data/occurrence/bien/bien-cfp-2022-04-27.rds") %>%
  mutate(
    dataset = "bien",
    species = queryName,
    key = as.character(key)
  ) %>%
  filter(species %in% spp_tbl$species) %>%
  select(dataset, key, species, longitude, latitude)

cch_tbl <- read_rds("data/occurrence/cch/cch-cfp-2022-05-02.rds") %>%
  mutate(
    dataset = "cch",
    species = queryName,
    key = as.character(key)
  ) %>%
  filter(species %in% spp_tbl$species) %>%
  select(dataset, key, species, longitude, latitude)

gbif_tbl <- read_rds("data/occurrence/gbif/gbif-cfp-2022-05-04.rds") %>%
  mutate(
    dataset = "gbif",
    species = queryName,
    key = as.character(key)
  ) %>%
  filter(species %in% spp_tbl$species) %>%
  select(dataset, key, species, longitude, latitude)

inat_tbl <- read_rds("data/occurrence/inat/inat-cfp-2022-05-04.rds") %>%
  mutate(
    dataset = "inat",
    # species = queryName,
    key = as.character(key)
  ) %>%
  filter(species %in% spp_tbl$species) %>%
  select(dataset, key, species, longitude, latitude)
```

Combine them and convert to sf.

```{r}
occ_sf <- bien_tbl %>%
  bind_rows(cch_tbl) %>%
  bind_rows(gbif_tbl) %>%
  bind_rows(inat_tbl) %>%
  st_as_sf(coords = c("longitude", "latitude"), crs = 4326) # WGS84
```

Compare sample sizes across data sets.

```{r}
occ_sf %>%
  as_tibble() %>%
  group_by(dataset) %>%
  summarise(
    record_number = n() %>% format(trim = TRUE, scientific = FALSE, big.mark = ","),
    species_number = unique(species) %>% length() %>% format(trim = TRUE, scientific = FALSE, big.mark = ",")
  ) %>%
  knitr::kable()
```

Compare occurrence locations across data sets. Randomly sample a proportion of records to save render time.

```{r}
set.seed(618)
prop_samp <- .1 # prop to sample and plot
ggplot() +
  geom_sf(
    data = rnaturalearth::ne_states(
      country = c("Mexico", "United States of America"),
      returnclass = "sf"
    ),
    fill = NA,
    color = alpha("black", .1)
  ) +
  geom_sf(data = cfp_sf, fill = "white", alpha = .5) +
  geom_sf(
    data = occ_sf %>% slice_sample(prop = prop_samp), # randomly sample certain proportion, otherwise too slow to render
    color = "black", alpha = .1, size = .1
  ) +
  labs(x = "Longitude", y = "Latitude") +
  coord_sf(xlim = c(-125, -115), ylim = c(28, 44)) +
  facet_wrap(. ~ dataset, nrow = 1)
rm(prop_samp)
```

## Get climate data

TODO: try hydrological year

### CHELSA

Download and process [CHELSA climatology data v2.1](https://chelsa-climate.org/downloads/). We used annual data of temperature and precipitation (see [metadata](https://chelsa-climate.org/bioclim/) below). Daily and monthly data are also available.

```{r, echo=FALSE}
tribble(
  ~shortname, ~longname, ~unit, ~scale, ~offset, ~explanation,
  "bio1", "mean annual air temperature", "°C", "0.1", "-273.15", "mean annual daily mean air temperatures averaged over 1 year",
  "bio12", "annual precipitation amount", "kg m^-2^ year^-1^", "0.1", "0", "accumulated precipitation amount over 1 year",
  "vpd_max", "max monthly vapor pressure deficit", "Pa", "0.1", "0", "the highest monthly vapor pressure deficit"
) %>%
  knitr::kable(caption = "CHELSA climatology data used in the project")
```

Note that precipitation unit, kg m^-2^ year^-1^, is equivalent to mm yr^-1^. 

Download data (not running).

```{r, eval=FALSE}
param_list <- c("bio1", "bio12", "vpd_max")
chelsa_path <- "data/climate/chelsa/"
for (param in param_list) {
  url <- paste0("https://os.zhdk.cloud.switch.ch/envicloud/chelsa/chelsa_V2/GLOBAL/climatologies/1981-2010/bio/CHELSA_", param, "_1981-2010_V.2.1.tif")
  httr::GET(url = url, httr::write_disk(path = paste0(chelsa_path, param, ".tif"), overwrite = TRUE))
  print(param)
}
```

Load raster data using the raster package.

```{r}
chelsa_ras <- raster::stack(
  "data/climate/chelsa/bio1.tif",
  "data/climate/chelsa/bio12.tif",
  "data/climate/chelsa/vpd_max.tif"
)
names(chelsa_ras) <- c("tmp", "ppt", "vpd")
raster::proj4string(chelsa_ras) # WGS84
```

### Daymet

Download and process Daymet data (not running).

```{r,eval=FALSE}
bbox <- st_bbox(cfp_sf)
param_list <- c("tmax", "tmin", "prcp")
for (param in param_list) {
  daymet_param_path <- paste0("data/climate/daymet/", param, "/")
  if (!dir.exists(daymet_param_path)) {
    dir.create(daymet_param_path, recursive = T)
  }
  for (year in 1980:2020) {
    # url<-paste0("https://thredds.daac.ornl.gov/thredds/fileServer/ornldaac/1840/daymet_v4_daily_na_",param,"_",year,".nc") # daily data are probably too much. takes too long to download and process.
    if (param == "prcp") {
      url <- paste0("https://thredds.daac.ornl.gov/thredds/fileServer/ornldaac/1855/daymet_v4_", param, "_monttl_na_", year, ".nc")
    }
    if (param %in% c("tmax", "tmin")) {
      url <- paste0("https://thredds.daac.ornl.gov/thredds/fileServer/ornldaac/1855/daymet_v4_", param, "_monavg_na_", year, ".nc")
    }
    httr::GET(url = url, httr::write_disk(path = paste0(daymet_param_path, year, ".nc"), overwrite = TRUE))
    print(paste0(param, ",", year))
  }
}
for (param in param_list) {
  daymet_param_path <- paste0("data/climate/daymet/", param, "/")
  files <- list.files(daymet_param_path, full.names = T)
  for (i in 1:length(files)) {
    file <- files[i]
    bri <- raster::brick(file)
    # potentially do other calculations
  }
}
```

### PRISM

Download and process PRISM using the prism package (not running).

```{r, eval=FALSE}
prism::prism_set_dl_dir("data/climate/prism/")
prism::get_prism_normals("tmean", "800m", annual = TRUE, keepZip = FALSE)
prism::get_prism_normals("ppt", "800m", annual = TRUE, keepZip = FALSE)
prism::get_prism_normals("vpdmax", "800m", annual = TRUE, keepZip = FALSE)
```

Load raster data using the raster package.

```{r}
prism::prism_set_dl_dir("data/climate/prism/")
prism_ras <- raster::stack(
  prism::prism_archive_subset("tmean", "annual normals", resolution = "800m") %>%
    prism::pd_to_file() %>%
    raster::raster(),
  prism::prism_archive_subset("ppt", "annual normals", resolution = "800m") %>%
    prism::pd_to_file() %>%
    raster::raster(),
  prism::prism_archive_subset("vpdmax", "annual normals", resolution = "800m") %>%
    prism::pd_to_file() %>%
    raster::raster()
)
names(prism_ras) <- c("tmp", "ppt", "vpd")
raster::proj4string(prism_ras) # NAD83
```

### Extract climate data at occurrence sites and then compare

Use GBIF occurrence data longitude and latitude to extract site climate values from CHELSA and PRISM rasters.

```{r, eval=FALSE}
gbif_sf_wgs84 <- read_rds("data/occurrence/gbif/gbif-cfp-2022-05-04.rds") %>%
  mutate(
    species = queryName,
    key = as.character(key)
  ) %>%
  filter(species %in% spp_tbl$species) %>%
  select(key, species, longitude, latitude) %>%
  st_as_sf(
    coords = c("longitude", "latitude"),
    crs = "+proj=longlat +datum=WGS84 +no_defs"
  )

gbif_sf_nad83 <- gbif_sf_wgs84 %>%
  st_transform(crs = "+proj=longlat +datum=NAD83 +no_defs")

chelsa_gbif_sf <- chelsa_ras %>%
  raster::extract(gbif_sf_wgs84) %>%
  as_tibble() %>%
  rename_with(~ str_c("chelsa_", .)) %>%
  bind_cols(gbif_sf_wgs84)

prism_gbif_sf <- prism_ras %>%
  raster::extract(gbif_sf_nad83) %>%
  as_tibble() %>%
  # mutate(vpd = vpd * 100) %>% # prism vpd * 100 = chelsa vpd unit
  rename_with(~ str_c("prism_", .)) %>%
  bind_cols(gbif_sf_nad83)

bind_cols(
  chelsa_gbif_sf %>%
    select(geometry, key, species, starts_with("chelsa_")),
  prism_gbif_sf %>%
    select(starts_with("prism_"))
) %>%
  write_rds("data/climate/climate-gbif-2022-05-04.rds")
```

Compare CHELSA and PRISM climate data at GBIF occurrence locations, by making scatter plots with correlation. 

```{r}
clim_gbif_tbl <- read_rds("data/climate/climate-gbif-2022-05-04.rds") %>%
  as_tibble() %>%
  drop_na() # PRISM = NA in Mexico

ggplot(clim_gbif_tbl, aes(chelsa_tmp, prism_tmp)) +
  geom_hex(bins = 100) +
  viridis::scale_fill_viridis() +
  geom_smooth(method = "lm", formula = y ~ x, se = FALSE, color = "red", lty = "dashed") +
  ggpubr::stat_cor(
    aes(label = paste(..r.label.., ..p.label.., sep = "~`,`~")),
    p.accuracy = 0.05,
    color = "red"
  ) +
  geom_abline(slope = 1, intercept = 0, color = "red") +
  coord_fixed() +
  labs(
    x = "CHELSA temperature (°C)",
    y = "PRISM temperature (°C)",
    fill = "Occurrence site"
  )

ggplot(clim_gbif_tbl, aes(chelsa_ppt, prism_ppt)) +
  geom_hex(bins = 100) +
  viridis::scale_fill_viridis() +
  geom_smooth(method = "lm", formula = y ~ x, se = FALSE, color = "red", lty = "dashed") +
  ggpubr::stat_cor(
    aes(label = paste(..r.label.., ..p.label.., sep = "~`,`~")),
    p.accuracy = 0.05,
    color = "red"
  ) +
  geom_abline(slope = 1, intercept = 0, color = "red") +
  coord_fixed() +
  labs(
    x = "CHELSA precipitation (mm)",
    y = "PRISM precipitation (mm)",
    fill = "Occurrence site"
  )

ggplot(clim_gbif_tbl, aes(chelsa_vpd, prism_vpd)) +
  geom_hex(bins = 100) +
  viridis::scale_fill_viridis() +
  geom_smooth(method = "lm", formula = y ~ x, se = FALSE, color = "red", lty = "dashed") +
  ggpubr::stat_cor(
    aes(label = paste(..r.label.., ..p.label.., sep = "~`,`~")),
    p.accuracy = 0.05,
    color = "red"
  ) +
  geom_abline(slope = 1, intercept = 0, color = "red") +
  coord_fixed() +
  labs(
    x = "CHELSA VPD max (Pa)",
    y = "PRISM VPD max (Pa)",
    fill = "Occurrence site"
  )
```

Making maps is possible but too time consuming.

```{r, eval=FALSE}
clim_long_sf <- read_rds("data/climate/climate-gbif-2022-05-02.rds") %>%
  pivot_longer(
    contains(match = c("chelsa", "prism")),
    names_to = "dataset_variable",
    values_to = "value"
  ) %>%
  separate(
    col = dataset_variable,
    into = c("dataset", "variable"),
    sep = "_"
  )

ggplot() +
  geom_sf(
    data = rnaturalearth::ne_states(
      country = c("Mexico", "United States of America"),
      returnclass = "sf"
    ),
    fill = NA,
    color = alpha("black", .1)
  ) +
  geom_sf(data = cfp_sf, fill = "white", alpha = .5) +
  geom_sf(
    data = clim_long_sf,
    aes(geometry = geometry, color = value),
    alpha = .1, size = .1
  ) +
  facet_wrap(variable ~ dataset) +
  scale_color_viridis() +
  labs(x = "Longitude", y = "Latitude") +
  coord_sf(xlim = c(-125, -115), ylim = c(28, 44))
```

## Quantify species climate niches

<!-- ### Compare niche estimation using all vs. CFP observations -->
<!-- ```{r} -->
<!-- bien_all_sf <- read_rds("data/occurrence/bien/bien-all-2022-04-27.rds") %>% -->
<!--   dplyr::select(species = queryName, longitude, latitude, key) %>% -->
<!--   mutate(key = as.character(key)) %>% -->
<!--   mutate(range = "all") %>% -->
<!--   st_as_sf(coords = c("longitude", "latitude"), crs = 4326) -->
<!-- bien_cfp_sf <- read_rds("data/occurrence/bien/bien-cfp-2022-04-27.rds") %>% -->
<!--   dplyr::select(species = queryName, longitude, latitude, key) %>% -->
<!--   mutate(key = as.character(key)) %>% -->
<!--   mutate(range = "cfp") %>% -->
<!--   st_as_sf(coords = c("longitude", "latitude"), crs = 4326) -->
<!-- range_compare_sf <- bind_rows(bien_all_sf, bien_cfp_sf) -->

<!-- ggplot(map_data("county", c("california", "nevada", "oregon"))) + -->
<!--   geom_polygon(aes(long, lat, group = group), -->
<!--     fill = "white", color = "grey75" -->
<!--   ) + -->
<!--   geom_sf(data = range_compare_sf, alpha = .5) + -->
<!--   geom_sf( -->
<!--     data = occ_sf %>% slice_sample(n = 1000), # randomly sample 1000, otherwise too slow to render -->
<!--     color = "black", alpha = .1, size = .1 -->
<!--   ) + -->
<!--   labs(x = "Longitude", y = "Latitude") + -->
<!--   facet_wrap(. ~ range, nrow = 1) -->
<!-- ``` -->

<!-- ```{r, eval=F} -->
<!-- range_compare_sf_reproj <- range_compare_sf %>% -->
<!--   st_transform(crs = st_crs(climate_list[["chelsa"]][[1]])) # WGS84 for CHELSA, NAD83 for PRISM -->

<!-- range_compare_clim_sf <- range_compare_sf_reproj %>% -->
<!--   mutate( -->
<!--     tmean = raster::extract(climate_list[["chelsa"]]$temp, range_compare_sf_reproj), -->
<!--     ppt = raster::extract(climate_list[["chelsa"]]$prcp, range_compare_sf_reproj), -->
<!--     vpdmax = raster::extract(climate_list[["chelsa"]]$vpd, range_compare_sf_reproj) -->
<!--   ) -->

<!-- write_rds(range_compare_clim_sf, "data/climate/range_comparison_with_climate_data.rds") -->
<!-- ``` -->

<!-- Compare quantiles of three climatic variables using data from full range and CFP. -->
<!-- ```{r} -->
<!-- range_compare_clim_summary <- read_rds("data/climate/range_comparison_with_climate_data.rds") %>% -->
<!--   as_tibble() %>% -->
<!--   dplyr::select(species, range, tmean, ppt, vpdmax) %>% -->
<!--   gather(key = "var", value = "value", -species, -range) %>% -->
<!--   group_by(species, range, var) %>% -->
<!--   summarise( -->
<!--     q5 = quantile(value, 0.05, na.rm = T), -->
<!--     q25 = quantile(value, 0.25, na.rm = T), -->
<!--     q50 = quantile(value, 0.5, na.rm = T), -->
<!--     q75 = quantile(value, 0.75, na.rm = T), -->
<!--     q95 = quantile(value, 0.95, na.rm = T) -->
<!--   ) %>% -->
<!--   gather(key = "quantile", value = "value", -species, -range, -var) %>% -->
<!--   spread(key = "range", value = "value") -->

<!-- ggplot(range_compare_clim_summary) + -->
<!--   geom_point(aes(x = all, y = cfp), alpha = 0.5) + -->
<!--   facet_wrap(. ~ var * quantile, scales = "free", ncol = 5) + -->
<!--   geom_abline(intercept = 0, slope = 1, col = "red") + -->
<!--   theme_classic() -->
<!-- ``` -->

### Individual species

Visualize individual species occurrence in climate space.

```{r, eval=FALSE}
# read combined GBIF and CHELSA data
gbif_chelsa_sf <- read_rds("data/climate/climate-gbif-2022-05-04.rds") %>%
  select(geometry, key, species, tmp = chelsa_tmp, ppt = chelsa_ppt, vpd = chelsa_vpd) %>%
  st_as_sf(crs = "+proj=longlat +datum=WGS84 +no_defs")

# check species lists
sp_gbif_vec <- gbif_chelsa_sf %>%
  pull(species) %>%
  unique() %>%
  sort()
sp_tab_vec <- spp_tbl %>%
  pull(species) %>%
  unique() %>%
  sort()
sp_gbif_vec %in% sp_tab_vec

# gbif summary
tmp_rng <- range(gbif_chelsa_sf$tmp)
ppt_rng <- range(gbif_chelsa_sf$ppt)
n_occ_tot <- nrow(gbif_chelsa_sf)
# exp data summary
exp_tbl <- read_rds("data/community/all-experimental-data.rds")
n_exp_tot <- nrow(exp_tbl)
# obs data summary
obs_tbl <- read_rds("data/community/all-observational-data.rds")
n_obs_tot <- nrow(obs_tbl)
niche_gg <- vector(mode = "list")

for (i in seq_along(sp_gbif_vec)) {
  sp <- sp_gbif_vec[i]
  occ_sp_sf <- filter(gbif_chelsa_sf, species == sp)

  occ_sp_stat <- occ_sp_sf %>%
    as_tibble() %>%
    summarise(
      occ_n = n(),
      tmp_occ_mean = mean(tmp, na.rm = TRUE),
      tmp_occ_sd = sd(tmp, na.rm = TRUE),
      ppt_occ_mean = mean(ppt, na.rm = TRUE),
      ppt_occ_sd = sd(ppt, na.rm = TRUE)
    )
  n_exp_sp <- exp_tbl %>%
    filter(species == sp) %>%
    nrow()
  n_obs_sp <- obs_tbl %>%
    filter(species == sp) %>%
    nrow()

  occ_geog <- ggplot() +
    geom_sf(
      data = rnaturalearth::ne_states(
        country = c("Mexico", "United States of America"),
        returnclass = "sf"
      ),
      fill = NA,
      color = alpha("black", .1)
    ) +
    geom_sf(data = cfp_sf, fill = "white", alpha = .5) +
    geom_sf(data = occ_sp_sf, alpha = .1, size = .5) +
    labs(x = "Longitude", y = "Latitude", title = sp) +
    coord_sf(xlim = c(-125, -115), ylim = c(28, 44)) +
    theme(plot.title = element_text(face = "italic"))

  occ_clim <- ggplot(occ_sp_sf, aes(tmp, ppt)) +
    geom_point(alpha = .5, size = .5) +
    geom_rug(alpha = .5) +
    stat_ellipse(col = "red") +
    geom_point(
      data = occ_sp_stat,
      aes(x = tmp_occ_mean, y = ppt_occ_mean),
      shape = 3, col = "red", size = 10
    ) +
    lims(x = tmp_rng, y = ppt_rng) +
    # scale_y_log10() + # log scale ppt
    labs(
      x = "Mean annual temperature (°C)", y = "Annual precipitation (mm)",
      title = str_c(
        "n_occ = ", occ_sp_stat$occ_n, " (", round(occ_sp_stat$occ_n / n_occ_tot * 100, digits = 3), "%)\n",
        "n_exp = ", n_exp_sp, " (", round(n_exp_sp / n_exp_tot * 100, digits = 3), "%)\n",
        "n_obs = ", n_obs_sp, " (", round(n_obs_sp / n_obs_tot * 100, digits = 3), "%)"
      )
    )

  print(sp)
  niche_gg[[i]] <- occ_geog + occ_clim # no need to print(); will slow down
}

names(niche_gg) <- sp_gbif_vec
```

Print all species into a multi-page PDF.

```{r, eval=FALSE}
# runtime ~= 4 min
pdf("figures/species-climate-niche-2022-05-04.pdf", width = 8, height = 8 * .618)
print(niche_gg)
dev.off()
```

### All species

Summarize species climate niches (mean, sd, etc.).

```{r}
niche_tbl <- read_rds("data/climate/climate-gbif-2022-05-04.rds") %>%
  select(key, species, tmp = chelsa_tmp, ppt = chelsa_ppt, vpd = chelsa_vpd) %>%
  group_by(species) %>%
  summarize(
    occ_n = n(),
    tmp_occ_mean = mean(tmp, na.rm = TRUE),
    tmp_occ_median = median(tmp, na.rm = TRUE),
    tmp_occ_lwr = quantile(tmp, .05, na.rm = TRUE),
    tmp_occ_upr = quantile(tmp, .95, na.rm = TRUE), # hot limit, suggested by Susan Harrison
    tmp_occ_sd = sd(tmp, na.rm = TRUE),
    ppt_occ_mean = mean(ppt, na.rm = TRUE),
    ppt_occ_median = median(ppt, na.rm = TRUE),
    ppt_occ_lwr = quantile(ppt, .05, na.rm = TRUE), # dry limit, suggested by Susan Harrison
    ppt_occ_upr = quantile(ppt, .95, na.rm = TRUE),
    ppt_occ_sd = sd(ppt, na.rm = TRUE),
    vpd_occ_mean = mean(vpd, na.rm = TRUE),
    vpd_occ_median = median(vpd, na.rm = TRUE),
    vpd_occ_lwr = quantile(vpd, .05, na.rm = TRUE),
    vpd_occ_upr = quantile(vpd, .95, na.rm = TRUE),
    vpd_occ_sd = sd(vpd, na.rm = TRUE),
  )
```

These different summary statistics (mean, median, upper, and lower quantiles) are highly and significantly correlated.

```{r fig.cap="Species temperature niche statistics (°C)"}
niche_tbl %>%
  select(tmp_occ_mean, tmp_occ_median, tmp_occ_lwr, tmp_occ_upr) %>%
  GGally::ggpairs(
    title = "Species temperature niche (°C)",
    columnLabels = c("Mean", "Median", "Lower limit (5%)", "Upper limit (95%)"),
  )
```

```{r fig.cap="Species precipitation niche statistics (mm)"}
niche_tbl %>%
  select(ppt_occ_mean, ppt_occ_median, ppt_occ_lwr, ppt_occ_upr) %>%
  GGally::ggpairs(
    title = "Species precipitation niche (mm)",
    columnLabels = c("Mean", "Median", "Lower limit (5%)", "Upper limit (95%)")
  )
```

```{r fig.cap="Species VPD max niche statistics (Pa)"}
niche_tbl %>%
  select(vpd_occ_mean, vpd_occ_median, vpd_occ_lwr, vpd_occ_upr) %>%
  GGally::ggpairs(
    title = "Species VPD max niche (Pa)",
    columnLabels = c("Mean", "Median", "Lower limit (5%)", "Upper limit (95%)")
  )
```

Different dimensions of the niche space (temperature, precipitation, and VPD max) are also correlated (using mean as summary).

```{r fig.cap="Correlation of species niche dimensions"}
niche_tbl %>%
  select(tmp_occ_mean, ppt_occ_mean, vpd_occ_mean) %>%
  GGally::ggpairs(
    title = "Species niche dimensions",
    columnLabels = c("Temperature (°C)", "Precipitation (mm)", "VPD max (Pa)")
  )
```

With all the correlations, we can safely use temperature and precipitation to visualize species niches in climate space. Note the strong negative correlation between temperature and precipitation (r = `r with(niche_tbl, cor(tmp_occ_mean, ppt_occ_mean)) %>% format(digits = 3)`, p = `r with(niche_tbl, cor.test(tmp_occ_mean, ppt_occ_mean))$p.value %>% format(digits = 3)`).

```{r fig.cap="Species climate niches, with mean (point) and standard error (crossbar)"}
(niche_tbl %>%
  ggplot(aes(text = species)) +
  geom_point(aes(tmp_occ_mean, ppt_occ_mean), alpha = .5) +
  geom_errorbarh(aes(xmin = tmp_occ_mean - tmp_occ_sd / sqrt(occ_n), xmax = tmp_occ_mean + tmp_occ_sd / sqrt(occ_n), y = ppt_occ_mean), alpha = .3) +
  geom_errorbar(aes(x = tmp_occ_mean, ymin = ppt_occ_mean - ppt_occ_sd / sqrt(occ_n), ymax = ppt_occ_mean + ppt_occ_sd / sqrt(occ_n)), alpha = .3) +
  labs(
    x = "Species occurrence mean temperature (°C)",
    y = "Species occurrence mean precipitation (mm)"
  )
) %>%
  plotly::ggplotly(tooltip = "text")
```

This figure compares well with Josie's estimates. 

```{r, fig.cap="Species climate niches (mean and standard error) estimated by Josie"}
(read_csv("data/archives/CAGrasslandCommunityChange-master/Analysis/CTI Data/AllSite_CTI_08_2020.csv") %>%
  filter(
    species.name != "Linanthus jepsonii",
    species.name != "Linanthus latisectus",
    relcov >= 0
  ) %>%
  dplyr::select(species = species.name, guild, tmp = meanT, ppt = meanp) %>%
  distinct() %>%
  ggplot(aes(tmp, ppt, text = species)) +
  geom_point(alpha = .5) +
  # geom_smooth(method = "lm", aes(tmp, ppt)) +
  labs(
    x = "Species occurrence mean temperature (°C)",
    y = "Species occurrence mean precipitation (mm)"
  )
) %>%
  plotly::ggplotly(tooltip = "text")
```

Save niche estimates with mean and SD statistics.

```{r}
niche_tbl %>%
  select(species, occ_n, tmp_occ_mean, tmp_occ_sd, ppt_occ_mean, ppt_occ_sd, vpd_occ_mean, vpd_occ_sd) %>%
  write_rds("data/occurrence/niche-estimates-cfp-2022-05-04.rds")
```
