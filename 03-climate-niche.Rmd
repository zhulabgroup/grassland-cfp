# Climate niche estimation

Setup and load packages.

```{r, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, eval = TRUE)
```

```{r}
library(tidyverse)
library(patchwork)
library(sf)
```

## Get occurrence data

The first question is what the geographic extent that we search for occurrence records. Joise used the state of California for convenience, but it seems to make more sense using an ecological, not administrative, boundary. We thought about using NEON domains. After much discussion, we decided to use the [biodiversity hotspots](https://www.cepf.net/our-work/biodiversity-hotspots). The most relevant one is California Floristic Province (CFP). Study sites seem to distribute nicely across CFP. 

```{r}
site_sf <- read_rds("data/community/site-info.rds")
site_sf %>%
  as_tibble() %>% # drop geometry
  knitr::kable()
```

Make a map overlaying sites with CFP and admin boundaries. 

```{r}
cfp_sf <- sf::st_read("data/occurrence/hotspots/hotspots_2016_1.shp") %>%
  filter(
    NAME == "California Floristic Province",
    Type == "hotspot area"
  )

(ggplot(map_data("county", c("california", "nevada", "oregon"))) +
  geom_polygon(aes(long, lat, group = group),
    fill = "white", color = "grey75"
  ) +
  geom_sf(data = cfp_sf, alpha = .5) +
  geom_sf(data = site_sf, color = "red", aes(text = name)) +
  labs(x = "Longitude (deg)", y = "Latitude (deg)")
) %>%
  plotly::ggplotly(tooltip = "text")
```

### GBIF

Load the master species list.

```{r}
spp_tbl <- read_rds("data/community/match-species-table.rds") %>%
  filter(kingdom == "Plantae") %>%
  group_by(queryname) %>%
  slice_head(n = 1) %>% # choose the top 1
  ungroup() %>%
  dplyr::select(queryname, canonicalname, everything()) %>%
  distinct(canonicalname, scientificname)
```

Extract occurrence data from GBIF, using the species list. The query output is an object of class `occdat`. Convert it to nested data, then unnest the data. Save GBIF occurrence data to a file.

```{r, eval=FALSE}
library(foreach)
library(doSNOW)
num_cores <- 22 # socs-stats has 44 cores
cl <- makeCluster(num_cores)
registerDoSNOW(cl)
gbif_occ_box_list <-
  foreach(
    i = 1:length(spp_tbl$canonicalname),
    .packages = c("spocc", "sf", "tidyverse")
  ) %dopar% {
    sp <- spp_tbl$canonicalname[i]
    res <- occ(
      query = sp, from = "gbif", has_coords = TRUE, limit = 1e6,
      geometry = st_bbox(cfp_sf),
      gbifopts = list(
        hasGeospatialIssue = FALSE
      )
    )
    print(i)
    tibble(queryName = sp, gbif = res$gbif$data) %>%
      unnest(cols = c(gbif))
  }
gbif_occ_box_df <- bind_rows(gbif_occ_box_list)
occ_sf_box <- st_as_sf(
  x = gbif_occ_box_df %>% dplyr::select(key, longitude, latitude),
  coords = c("longitude", "latitude"),
  crs = 4326
)
occ_sf <- st_intersection(occ_sf_box, cfp_sf)
gbif_occ_df <- gbif_occ_box_df %>%
  right_join(as_tibble(occ_sf) %>% dplyr::select(key), by = "key")
write_rds(gbif_occ_df, "data/occurrence/gbif/all-spp-cfp-2022-04-18.rds")
```

Read GBIF occurrence data as a sf object. 

```{r}
occ_sf <- read_rds("data/occurrence/gbif/all-spp-cfp-2022-04-18.rds") %>%
  st_as_sf(coords = c("longitude", "latitude"), crs = 4326) # WGS84
```

In total, GBIF has `r nrow(occ_sf) %>% format(trim = TRUE, scientific = FALSE, big.mark = ",")` records for `r unique(occ_sf$species) %>% length() %>% format(trim = TRUE, scientific = FALSE, big.mark = ",")` species. Make a map to show all occurrence locations (randomly sample 10% records to save render time).

```{r}
ggplot(map_data("county", c("california", "nevada", "oregon"))) +
  geom_polygon(aes(long, lat, group = group),
    fill = "white", color = "grey75"
  ) +
  geom_sf(data = cfp_sf, alpha = .5) +
  geom_sf(
    data = occ_sf %>% slice_sample(prop = .1), # randomly sample 10%, otherwise too slow to render
    color = "black", alpha = .1, size = .1
  ) +
  labs(x = "Longitude (deg)", y = "Latitude (deg)")
```

### iNaturalist

### BIEN

### eJepson

eJepson might be more accurate compared to iNat and GBIF.

## Get climate data

TODO: try hydrological year

### CHELSA

Download and process [CHELSA climatology data v2.1](https://chelsa-climate.org/downloads/). We used annual data of temperature and precipitation (see [metadata](https://chelsa-climate.org/bioclim/) below). Daily and monthly data are also available.

```{r, echo=FALSE}
tribble(
  ~shortname, ~longname, ~unit, ~scale, ~offset, ~explanation,
  "bio1", "mean annual air temperature", "Â°C", "0.1", "-273.15", "mean annual daily mean air temperatures averaged over 1 year",
  "bio12", "annual precipitation amount", "kg m^-2^ year^-1^", "0.1", "0", "accumulated precipitation amount over 1 year",
  "vpd_max", "max monthly vapor pressure deficit", "Pa", "0.1", "0", "the highest monthly vapor pressure deficit"
) %>%
  knitr::kable(caption = "CHELSA climatology data used in the project")
```

Note that precipitation unit, kg m^-2^ year^-1^, is equivalent to mm yr^-1^. 

Download data (not running).

```{r, eval=FALSE}
param_list <- c("bio1", "bio12", "vpd_max")
chelsa_path <- "data/climate/chelsa/"
for (param in param_list) {
  url <- paste0("https://os.zhdk.cloud.switch.ch/envicloud/chelsa/chelsa_V2/GLOBAL/climatologies/1981-2010/bio/CHELSA_", param, "_1981-2010_V.2.1.tif")
  httr::GET(url = url, httr::write_disk(path = paste0(chelsa_path, param, ".tif"), overwrite = TRUE))
  print(param)
}
```

Load raster data using the raster package.

```{r}
tmean_ras <- raster::raster("data/climate/chelsa/bio1.tif")
ppt_ras <- raster::raster("data/climate/chelsa/bio12.tif")
vpdmax_ras <- raster::raster("data/climate/chelsa/vpd_max.tif")
raster::proj4string(tmean_ras) # check that projection is WGS84
```

### Daymet

Download and process Daymet data (not running).

```{r,eval=FALSE}
bbox <- st_bbox(cfp_sf)
param_list <- c("tmax", "tmin", "prcp")
for (param in param_list) {
  daymet_param_path <- paste0("data/climate/daymet/", param, "/")
  if (!dir.exists(daymet_param_path)) {
    dir.create(daymet_param_path, recursive = T)
  }
  for (year in 1980:2020) {
    # url<-paste0("https://thredds.daac.ornl.gov/thredds/fileServer/ornldaac/1840/daymet_v4_daily_na_",param,"_",year,".nc") # daily data are probably too much. takes too long to download and process.
    if (param == "prcp") {
      url <- paste0("https://thredds.daac.ornl.gov/thredds/fileServer/ornldaac/1855/daymet_v4_", param, "_monttl_na_", year, ".nc")
    }
    if (param %in% c("tmax", "tmin")) {
      url <- paste0("https://thredds.daac.ornl.gov/thredds/fileServer/ornldaac/1855/daymet_v4_", param, "_monavg_na_", year, ".nc")
    }
    httr::GET(url = url, httr::write_disk(path = paste0(daymet_param_path, year, ".nc"), overwrite = TRUE))
    print(paste0(param, ",", year))
  }
}
for (param in param_list) {
  daymet_param_path <- paste0("data/climate/daymet/", param, "/")
  files <- list.files(daymet_param_path, full.names = T)
  for (i in 1:length(files)) {
    file <- files[i]
    bri <- raster::brick(file)
    # potentially do other calculations
  }
}
```

### PRISM

Download and process PRISM using the prism package (not running).

```{r, eval=FALSE}
prism::prism_set_dl_dir("data/climate/prism/")
prism::get_prism_normals("tmean", "800m", annual = TRUE, keepZip = FALSE)
prism::get_prism_normals("ppt", "800m", annual = TRUE, keepZip = FALSE)
prism::get_prism_normals("vpdmax", "800m", annual = TRUE, keepZip = FALSE)
```

Load raster data using the raster package.

```{r, eval=FALSE}
tmean_ras <- prism::prism_archive_subset("tmean", "annual normals", resolution = "800m") %>%
  prism::pd_to_file() %>%
  raster::raster()
ppt_ras <- prism::prism_archive_subset("ppt", "annual normals", resolution = "800m") %>%
  prism::pd_to_file() %>%
  raster::raster()
vpdmax_ras <- prism::prism_archive_subset("vpdmax", "annual normals", resolution = "800m") %>%
  prism::pd_to_file() %>%
  raster::raster()
```

## Extract data at occurrence sites

Use GBIF occurrence data longitude and latitude to extract site climate values from CHELSA rasters. But first, convert GBIF coordinates in WGS84 to the projection of CHELSA rasters.

```{r}
occ_sf <- occ_sf %>%
  st_transform(crs = st_crs(tmean_ras)) %>% # WGS84 for CHELSA, NAD83 for PRISM
  dplyr::select(species = queryName)
```

```{r}
occ_sf <- occ_sf %>%
  mutate(
    tmean = raster::extract(tmean_ras, occ_sf),
    ppt = raster::extract(ppt_ras, occ_sf),
    vpdmax = raster::extract(vpdmax_ras, occ_sf)
  )
```

## Quantify species climate niches

### Individual species

Visualize individual species occurrence in climate space.

```{r, eval=FALSE}
# gbif summary
tmean_rng <- range(occ_sf$tmean)
ppt_rng <- range(occ_sf$ppt)
n_occ_tot <- nrow(occ_sf)
# exp data summary
exp_tbl <- read_rds("data/community/all-experimental-data.rds")
n_exp_tot <- nrow(exp_tbl)
# obs data summary
obs_tbl <- read_rds("data/community/all-observational-data.rds")
n_obs_tot <- nrow(obs_tbl)
niche_gg <- vector(mode = "list")

for (i in 1:length(unique(occ_sf$species))) {
  sp <- unique(occ_sf$species)[i]
  occ_sp_sf <- filter(occ_sf, species == sp)

  occ_sp_stat <- occ_sp_sf %>%
    as_tibble() %>%
    summarise(
      occ_n = n(),
      tmean_occ_mean = mean(tmean, na.rm = TRUE),
      tmean_occ_sd = sd(tmean, na.rm = TRUE),
      ppt_occ_mean = mean(ppt, na.rm = TRUE),
      ppt_occ_sd = sd(ppt, na.rm = TRUE)
    )
  n_exp_sp <- exp_tbl %>%
    filter(species == sp) %>%
    nrow()
  n_obs_sp <- obs_tbl %>%
    filter(species == sp) %>%
    nrow()

  occ_geog <- ggplot(map_data("county", c("california", "nevada", "oregon"))) +
    geom_polygon(aes(long, lat, group = group),
      fill = "white", color = "grey75"
    ) +
    geom_sf(data = cfp_sf, alpha = .5) +
    geom_sf(data = occ_sp_sf, alpha = .1, size = .5) +
    labs(x = "Longitude (deg)", y = "Latitude (deg)", title = sp) +
    theme(plot.title = element_text(face = "italic"))

  occ_clim <- ggplot(occ_sp_sf, aes(tmean, ppt)) +
    geom_point(alpha = .5, size = .5) +
    geom_rug(alpha = .5) +
    stat_ellipse(col = "red") +
    geom_point(
      data = occ_sp_stat,
      aes(x = tmean_occ_mean, y = ppt_occ_mean),
      shape = 3, col = "red", size = 10
    ) +
    lims(x = tmean_rng, y = ppt_rng) +
    # scale_y_log10() + # log scale ppt
    labs(
      x = "Mean annual temperature (degC)", y = "Annual precipitation (mm)",
      title = str_c(
        "n_occ = ", occ_sp_stat$occ_n, " (", round(occ_sp_stat$occ_n / n_occ_tot * 100, digits = 3), "%)\n",
        "n_exp = ", n_exp_sp, " (", round(n_exp_sp / n_exp_tot * 100, digits = 3), "%)\n",
        "n_obs = ", n_obs_sp, " (", round(n_obs_sp / n_obs_tot * 100, digits = 3), "%)"
      )
    )

  print(sp)
  niche_gg[[i]] <- occ_geog + occ_clim # no need to print(); will slow down
}

names(niche_gg) <- unique(occ_sf$species)
```

Print all species into a multi-page PDF.

```{r, eval=FALSE}
# runtime ~= 4 min
pdf("figures/species-climate-niche-2022-04-18.pdf", width = 8, height = 8 * .618)
print(niche_gg)
dev.off()
```

### All species

Summarize species climate niches (mean, sd, etc.).

```{r}
niche_tbl <- occ_sf %>%
  as_tibble() %>% # drop sf geometry--too slow and not needed for this summary
  group_by(species) %>%
  summarize(
    occ_n = n(),
    tmean_occ_mean = mean(tmean, na.rm = TRUE),
    tmean_occ_median = median(tmean, na.rm = TRUE),
    tmean_occ_lwr = quantile(tmean, .05, na.rm = TRUE),
    tmean_occ_upr = quantile(tmean, .95, na.rm = TRUE), # hot limit, suggested by Susan Harrison
    tmean_occ_sd = sd(tmean, na.rm = TRUE),
    ppt_occ_mean = mean(ppt, na.rm = TRUE),
    ppt_occ_median = median(ppt, na.rm = TRUE),
    ppt_occ_lwr = quantile(ppt, .05, na.rm = TRUE), # dry limit, suggested by Susan Harrison
    ppt_occ_upr = quantile(ppt, .95, na.rm = TRUE),
    ppt_occ_sd = sd(ppt, na.rm = TRUE),
    vpdmax_occ_mean = mean(vpdmax, na.rm = TRUE),
    vpdmax_occ_median = median(vpdmax, na.rm = TRUE),
    vpdmax_occ_lwr = quantile(vpdmax, .05, na.rm = TRUE),
    vpdmax_occ_upr = quantile(vpdmax, .95, na.rm = TRUE),
    vpdmax_occ_sd = sd(vpdmax, na.rm = TRUE),
  )
```

How correlated are these different summary statistics (mean, median, upper, and lower quantiles)?

```{r fig.cap="Species temperature niche statistics (degC)"}
niche_tbl %>%
  select(tmean_occ_mean, tmean_occ_median, tmean_occ_lwr, tmean_occ_upr) %>%
  GGally::ggpairs(
    title = "Species temperature niche (degC)",
    columnLabels = c("Mean", "Median", "Lower limit (5%)", "Upper limit (95%)"),
  )
```

```{r fig.cap="Species precipitation niche statistics (mm)"}
niche_tbl %>%
  select(ppt_occ_mean, ppt_occ_median, ppt_occ_lwr, ppt_occ_upr) %>%
  GGally::ggpairs(
    title = "Species precipitation niche (mm)",
    columnLabels = c("Mean", "Median", "Lower limit (5%)", "Upper limit (95%)")
  )
```

```{r fig.cap="Species VPDmax niche statistics (Pa)"}
niche_tbl %>%
  select(vpdmax_occ_mean, vpdmax_occ_median, vpdmax_occ_lwr, vpdmax_occ_upr) %>%
  GGally::ggpairs(
    title = "Species VPDmax niche (Pa)",
    columnLabels = c("Mean", "Median", "Lower limit (5%)", "Upper limit (95%)")
  )
```

How correlated are these different dimensions of the niche space (using mean as summary)?

```{r}
niche_tbl %>%
  select(tmean_occ_mean, ppt_occ_mean, vpdmax_occ_mean) %>%
  GGally::ggpairs(
    title = "Species niche dimensions",
    columnLabels = c("Temperature (degC)", "Precipitation (mm)", "VPDmax (Pa)")
  )
```

Visualize species niches in climate space.

```{r kai-niche-mean-sd, fig.cap="Species climate niches; mean and standard error"}
(niche_tbl %>%
  ggplot(aes(text = species)) +
  geom_point(aes(tmean_occ_mean, ppt_occ_mean), alpha = .5) +
  geom_errorbarh(aes(xmin = tmean_occ_mean - tmean_occ_sd / sqrt(occ_n), xmax = tmean_occ_mean + tmean_occ_sd / sqrt(occ_n), y = ppt_occ_mean), alpha = .3) +
  geom_errorbar(aes(x = tmean_occ_mean, ymin = ppt_occ_mean - ppt_occ_sd / sqrt(occ_n), ymax = ppt_occ_mean + ppt_occ_sd / sqrt(occ_n)), alpha = .3) +
  labs(
    x = "Species occurrence mean temperature (degC)",
    y = "Species occurrence mean precipitation (mm)"
  )
) %>%
  plotly::ggplotly(tooltip = "text")
```

This figure compares well with Josie's estimates. 

```{r, fig.cap="Species climate niches (mean and standard error) estimated by Josie"}
(read_csv("data/archives/CAGrasslandCommunityChange-master/Analysis/CTI Data/AllSite_CTI_08_2020.csv") %>%
  filter(
    species.name != "Linanthus jepsonii",
    species.name != "Linanthus latisectus",
    relcov >= 0
  ) %>%
  dplyr::select(species = species.name, guild, tmp = meanT, ppt = meanp) %>%
  distinct() %>%
  ggplot(aes(tmp, ppt, text = species)) +
  geom_point(alpha = .5) +
  # geom_smooth(method = "lm", aes(tmp, ppt)) +
  labs(
    x = "Species occurrence mean temperature (degC)",
    y = "Species occurrence mean precipitation (mm)"
  )
) %>%
  plotly::ggplotly(tooltip = "text")
```

Save niche estimates with mean and SD statistics.

```{r}
niche_tbl %>%
  select(species, occ_n, tmean_occ_mean, tmean_occ_sd, ppt_occ_mean, ppt_occ_sd, vpdmax_occ_mean, vpdmax_occ_sd) %>%
  write_rds("data/occurrence/niche-estimates-cfp-2022-04-18.rds")
```
