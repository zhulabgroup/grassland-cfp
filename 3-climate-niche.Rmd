---
title: "Climate niche estimation"
date: "`r format(Sys.time(), '%B %d, %Y')`"
editor_options: 
  chunk_output_type: console
output:
  bookdown::html_document2: 
    fig_caption: true
    number_sections: true
    global_numbering: true
  bookdown::word_document2: 
    fig_caption: true
    number_sections: true
    global_numbering: true
---

```{r setup, echo=FALSE, message=FALSE}
source("scripts/utils/setup.R")
```

# Get occurrence data

The first question is what the geographic extent that we search for occurrence records. Joise used the state of California for convenience, but it seems to make more sense using an ecological, not administrative, boundary. We thought about using NEON domains. After much discussion, we decided to use the [biodiversity hotspots](https://www.cepf.net/our-work/biodiversity-hotspots). The most relevant one is California Floristic Province (CFP). Study sites seem to distribute nicely across CFP. 
```{r site-info}
site_sf <- read_rds(.path$geo_site)
site_sf %>%
  as_tibble() %>% # drop geometry
  knitr::kable()
```

Make a map overlaying sites with CFP and admin boundaries from [Natural Earth](https://www.naturalearthdata.com/). 

```{r site-map, fig.cap="Site map"}
source("scripts/plot-site-map.R")
site_gg
rm(list = ls())
```

Load two species tables. 

1. All the species from community data (experimental and observational).
1. Species consolidation table.

```{r}
spp_comm_tbl <- read_rds("data/community/all-experimental-data.rds") %>%
  dplyr::select(species) %>%
  bind_rows(
    read_rds("data/community/all-observational-data.rds") %>%
      dplyr::select(species)
  ) %>%
  distinct(species) %>%
  arrange(species)

googlesheets4::gs4_deauth()
spp_consol_tbl <- googlesheets4::read_sheet("1ez43lbFMsTJwmkW_23icDabt30ttDhVZ-1vK8Ts_Mck", sheet = "Consolidation", na = c("", "NA"))

spp_tbl <- spp_comm_tbl %>%
  rename("query_name" = "species") %>%
  bind_cols("consolidated_name" = as.character(NA)) %>%
  bind_rows(
    spp_consol_tbl %>%
      rename(
        "query_name" = "old_species_name",
        "consolidated_name" = "new_species_name"
      )
  ) %>%
  filter(!str_detect(query_name, "DUMMY")) %>%
  arrange(query_name) %>%
  distinct(query_name, consolidated_name)

rm(spp_comm_tbl, spp_consol_tbl)
```

## GBIF

Extract occurrence data from GBIF, using the species list. The query output is an object of class `occdat`. Convert it to nested data, then unnest the data. Save GBIF occurrence data to a file.

```{r, eval=FALSE}
# ~ 15 min to run
library(foreach)
library(doSNOW)
num_cores <- 22 # socs-stats has 44 cores
cl <- makeCluster(num_cores)
registerDoSNOW(cl)
gbif_box_ls <-
  foreach(
    i = 1:length(spp_tbl$query_name),
    .packages = c("spocc", "sf", "tidyverse")
  ) %dopar% {
    sp <- spp_tbl$query_name[i]
    res <- occ(
      query = sp, from = "gbif", has_coords = TRUE, limit = 1e6,
      geometry = st_bbox(cfp_sf),
      gbifopts = list(
        # occ_options(from = "gbif", where = "console")
        hasGeospatialIssue = FALSE
      )
    )
    print(i)
    tibble(queryName = sp, gbif = res$gbif$data) %>%
      unnest(cols = c(gbif))
  }
stopCluster(cl)

gbif_box_tbl <- bind_rows(gbif_box_ls) # collapse from list to tibble

gbif_cfp_tbl <- gbif_box_tbl %>%
  select(key, longitude, latitude) %>%
  st_as_sf(coords = c("longitude", "latitude"), crs = 4326) %>%
  st_intersection(cfp_sf) %>% # find GBIF and CFP intersection
  as_tibble() %>% # drop geometry
  select(key) %>% # use key to join (fast)
  right_join(gbif_box_tbl, ., by = "key")

write_rds(gbif_cfp_tbl, "data/occurrence/gbif/gbif-cfp-2022-09-18.rds")

rm(cl, num_cores, gbif_box_ls, gbif_box_tbl, gbif_cfp_tbl)
```

Note that GBIF depends on download dates. So we'll keep the download file with date stamp.

Consolidate species names in GBIF.

```{r, eval=FALSE}
read_rds("data/occurrence/gbif/gbif-cfp-2022-09-18.rds") %>%
  left_join(spp_tbl, by = c("queryName" = "query_name")) %>%
  select(consolidatedName = consolidated_name, everything()) %>%
  mutate(
    consolidatedName =
      ifelse(
        is.na(consolidatedName),
        queryName,
        consolidatedName
      )
  ) %>%
  write_rds("data/occurrence/gbif/gbif-consolidated-2022-09-18.rds")
```

Pointer to file name.

```{r}
gbif_file <- "data/occurrence/gbif/gbif-consolidated-2022-09-18.rds"
```

## iNaturalist

Not directly querying the data separately because:

1. Hard limit of 10,000 records
2. Very slow
3. May be blocked if running too many queries in a minute

```{r, eval=FALSE}
res <- occ(
  query = gbif_occ_df_today, from = "inat", has_coords = TRUE, limit = 10000,
  geometry = st_bbox(cfp_sf)
)
```

4. A recommended way to get a lot of data at once is to use the dataset of research grade observations submitted weekly to GBIF https://www.gbif.org/dataset/50c9509d-22c7-4a22-a47d-8c48425ef4a7

```{r, eval=FALSE}
read_rds(gbif_file) %>%
  filter(datasetName == "iNaturalist research-grade observations") %>%
  write_rds("data/occurrence/inat/inat-cfp-2022-09-18.rds")
```

Pointer to file name.

```{r}
inat_file <- "data/occurrence/inat/inat-cfp-2022-09-18.rds"
```

## BIEN

Retrieve all BIEN data then select those within CFP. Note, the code can't run because of BIEN server error, as of 5/2/2022.

```{r, eval=FALSE}
library(foreach)
library(doSNOW)
num_cores <- 22 # socs-stats has 44 cores
cl <- makeCluster(num_cores)
registerDoSNOW(cl)
bien_df_list <-
  foreach(
    i = 1:length(spp_tbl$query_name),
    .packages = c("BIEN", "tidyverse")
  ) %dopar% {
    sp <- spp_tbl$query_name[i]
    res <- BIEN_occurrence_species(species = sp)
    print(i)
    tibble(queryName = sp, res) %>%
      mutate(date_collected = as.Date(date_collected))
  }
bien_all_df <- bind_rows(bien_df_list) %>%
  mutate(key = row_number()) %>%
  drop_na(latitude, longitude)
stopCluster(cl)

bien_all_sf <- st_as_sf(
  x = bien_all_df %>% dplyr::select(key, longitude, latitude),
  coords = c("longitude", "latitude"),
  crs = 4326
)
bien_cfp_sf <- st_intersection(bien_all_sf, cfp_sf)
bien_cfp_df <- bien_all_df %>%
  right_join(as_tibble(bien_cfp_sf) %>% dplyr::select(key), by = "key")
write_rds(bien_all_df, "data/occurrence/bien/bien-all-2022-04-27.rds")
write_rds(bien_cfp_df, "data/occurrence/bien/bien-cfp-2022-04-27.rds")
```

Pointer to file name.

```{r}
bien_file <- "data/occurrence/bien/bien-cfp-2022-04-27.rds"
```

## eJepson (CCH)

eJepson might be more accurate compared to iNat and GBIF.

Download full dataset at https://www.cch2.org/portal/collections/harvestparams.php
(Searching within the bounding box of 55N-10N, 130W-50W.)

Keep records with species of interest and within CFP.

```{r, eval=FALSE}
cch_all_tbl <- read_csv("data/occurrence/cch/occurrences.csv") %>%
  filter(scientificName %in% spp_tbl$query_name) %>%
  drop_na(decimalLongitude, decimalLatitude) %>%
  select(
    queryName = scientificName,
    longitude = decimalLongitude,
    latitude = decimalLatitude,
    key = id
  ) %>%
  left_join(spp_tbl, by = c("queryName" = "query_name")) %>%
  mutate(species_name = ifelse(
    is.na(consolidated_name),
    queryName,
    consolidated_name
  )) %>%
  select(species_name, longitude, latitude, key)

cch_cfp_tbl <- cch_all_tbl %>%
  st_as_sf(coords = c("longitude", "latitude"), crs = 4326) %>%
  st_intersection(cfp_sf) %>% # find CCH and CFP intersection
  as_tibble() %>% # drop geometry
  select(key) %>% # use key to join (fast)
  right_join(cch_all_tbl, ., by = "key")

write_rds(cch_all_tbl, "data/occurrence/cch/cch-all-2022-07-12.rds")
write_rds(cch_cfp_tbl, "data/occurrence/cch/cch-cfp-2022-07-12.rds")

rm(cch_all_tbl, cch_cfp_tbl)
```

Pointer to file name.

```{r}
cch_file <- "data/occurrence/cch/cch-cfp-2022-07-12.rds"
```

## Compare occurrence data sets

Compare the above data sets, in alphabetical order, BIEN, CCH, GBIF, iNat.

```{r}
bien_tbl <- read_rds(bien_file) %>%
  mutate(
    dataset = "bien",
    species = queryName,
    key = as.character(key)
  ) %>%
  select(dataset, key, species, longitude, latitude)

cch_tbl <- read_rds(cch_file) %>%
  mutate(
    dataset = "cch",
    species = species_name,
    key = as.character(key)
  ) %>%
  select(dataset, key, species, longitude, latitude)

gbif_tbl <- read_rds(gbif_file) %>%
  mutate(
    dataset = "gbif",
    species = consolidatedName,
    key = as.character(key)
  ) %>%
  filter(coordinatePrecision < 0.01 | is.na(coordinatePrecision)) %>%
  filter(coordinateUncertaintyInMeters < 10000 | is.na(coordinateUncertaintyInMeters)) %>%
  filter(!coordinateUncertaintyInMeters %in% c(301, 3036, 999, 9999)) %>%
  select(dataset, key, species, longitude, latitude)

inat_tbl <- read_rds(inat_file) %>%
  mutate(
    dataset = "inat",
    species = consolidatedName,
    key = as.character(key)
  ) %>%
  filter(coordinatePrecision < 0.01 | is.na(coordinatePrecision)) %>%
  filter(coordinateUncertaintyInMeters < 10000 | is.na(coordinateUncertaintyInMeters)) %>%
  filter(!coordinateUncertaintyInMeters %in% c(301, 3036, 999, 9999)) %>%
  select(dataset, key, species, longitude, latitude)
```

Combine them and convert to sf.

```{r}
occ_sf <- bien_tbl %>%
  bind_rows(cch_tbl) %>%
  bind_rows(gbif_tbl) %>%
  bind_rows(inat_tbl) %>%
  st_as_sf(coords = c("longitude", "latitude"), crs = 4326) # WGS84
```

Compare sample sizes across data sets.

```{r}
occ_sf %>%
  as_tibble() %>%
  group_by(dataset) %>%
  summarise(
    record_number = n() %>% format(trim = TRUE, scientific = FALSE, big.mark = ","),
    species_number = unique(species) %>% length() %>% format(trim = TRUE, scientific = FALSE, big.mark = ",")
  ) %>%
  knitr::kable()
```

Compare occurrence locations across data sets. Randomly sample a proportion of records to save render time.

```{r}
set.seed(618)
prop_samp <- .1 # prop to sample and plot
ggplot() +
  geom_sf(
    data = rnaturalearth::ne_states(
      country = c("Mexico", "United States of America"),
      returnclass = "sf"
    ),
    fill = NA,
    color = alpha("black", .1)
  ) +
  geom_sf(data = cfp_sf, fill = "white", alpha = .5) +
  geom_sf(
    data = occ_sf %>% slice_sample(prop = prop_samp), # randomly sample certain proportion, otherwise too slow to render
    color = "black", alpha = .1, size = .1
  ) +
  labs(x = "Longitude", y = "Latitude") +
  coord_sf(xlim = c(-125, -115), ylim = c(28, 44)) +
  facet_wrap(. ~ dataset, nrow = 1)
rm(prop_samp)
```

Remove intermediate objects and all occurrence data (but leave GBIF file name pointers).

```{r}
rm(bien_tbl, cch_tbl, gbif_tbl, inat_tbl, occ_sf)
rm(bien_file, cch_file, inat_file)
```

# Get climate data

## CHELSA

Download and process [CHELSA climatology data v2.1](https://chelsa-climate.org/downloads/). We used annual data of temperature and precipitation (see [metadata](https://chelsa-climate.org/bioclim/) below). Daily and monthly data are also available.

```{r, echo=FALSE}
tribble(
  ~shortname, ~longname, ~unit, ~scale, ~offset, ~explanation,
  "bio1", "mean annual air temperature", "°C", "0.1", "-273.15", "mean annual daily mean air temperatures averaged over 1 year",
  "bio12", "annual precipitation amount", "kg m^-2^ year^-1^", "0.1", "0", "accumulated precipitation amount over 1 year",
  "vpd_max", "max monthly vapor pressure deficit", "Pa", "0.1", "0", "the highest monthly vapor pressure deficit"
) %>%
  knitr::kable(caption = "CHELSA climatology data used in the project")
```

Note that precipitation unit, kg m^-2^ year^-1^, is equivalent to mm yr^-1^. 

Download data (not running).

```{r, eval=FALSE}
param_list <- c("bio1", "bio12", "vpd_max")
chelsa_path <- "data/climate/chelsa/"
for (param in param_list) {
  url <- paste0("https://os.zhdk.cloud.switch.ch/envicloud/chelsa/chelsa_V2/GLOBAL/climatologies/1981-2010/bio/CHELSA_", param, "_1981-2010_V.2.1.tif")
  httr::GET(url = url, httr::write_disk(path = paste0(chelsa_path, param, ".tif"), overwrite = TRUE))
  print(param)
}
```

Load raster data using the raster package.

```{r}
chelsa_ras <- raster::stack(
  "data/climate/chelsa/bio1.tif",
  "data/climate/chelsa/bio12.tif",
  "data/climate/chelsa/vpd_max.tif"
)
names(chelsa_ras) <- c("tmp", "ppt", "vpd")
raster::proj4string(chelsa_ras) # WGS84
```

## PRISM

Download and process PRISM using the prism package (not running).

```{r, eval=FALSE}
prism::prism_set_dl_dir("data/climate/prism/")
prism::get_prism_normals("tmean", "800m", annual = TRUE, keepZip = FALSE)
prism::get_prism_normals("ppt", "800m", annual = TRUE, keepZip = FALSE)
prism::get_prism_normals("vpdmax", "800m", annual = TRUE, keepZip = FALSE)
```

Load raster data using the raster package.

```{r}
prism::prism_set_dl_dir("data/climate/prism/")
prism_ras <- raster::stack(
  prism::prism_archive_subset("tmean", "annual normals", resolution = "800m") %>%
    prism::pd_to_file() %>%
    raster::raster(),
  prism::prism_archive_subset("ppt", "annual normals", resolution = "800m") %>%
    prism::pd_to_file() %>%
    raster::raster(),
  prism::prism_archive_subset("vpdmax", "annual normals", resolution = "800m") %>%
    prism::pd_to_file() %>%
    raster::raster()
)
names(prism_ras) <- c("tmp", "ppt", "vpd")
raster::proj4string(prism_ras) # NAD83
```

## TerraClimate

Climatology data manually downloaded from http://thredds.northwestknowledge.net:8080/thredds/catalog/TERRACLIMATE_ALL/summaries/catalog.html

Calculate mean annual temperature, total annual precipitation, and maximum monthly vapor pressure deficit from monthly climatology.

```{r, eval=FALSE}
param_list <- c("tmp", "ppt", "vpd")
terraclim_path <- "data/climate/terraclimate/"
dir.create(terraclim_path, recursive = T)
for (param in param_list) {
  if (param == "tmp") {
    terraclim_stack1 <- raster::stack(
      paste0("data/climate/terraclimate/TerraClimate19812010_tmax.nc")
    )
    terraclim_stack2 <- raster::stack(
      paste0("data/climate/terraclimate/TerraClimate19812010_tmin.nc")
    )
    terraclim_ras_list <- vector(mode = "list", length = 12)
    for (m in 1:12) {
      terraclim_ras_list[[m]] <- mean(terraclim_stack1[[m]], terraclim_stack2[[m]])
    }
    terraclim_ras <- terraclim_ras_list %>%
      stack() %>%
      mean()
    writeRaster(terraclim_ras, "data/climate/terraclimate/tmp.tif", format = "GTiff", overwrite = TRUE)
  }

  if (param == "ppt") {
    terraclim_stack <- raster::stack(
      paste0("data/climate/terraclimate/TerraClimate19812010_ppt.nc")
    )
    terraclim_ras <- sum(terraclim_stack)
    writeRaster(terraclim_ras, "data/climate/terraclimate/ppt.tif", format = "GTiff", overwrite = TRUE)
  }

  if (param == "vpd") {
    terraclim_stack <- raster::stack(
      paste0("data/climate/terraclimate/TerraClimate19812010_vpd.nc")
    )
    terraclim_ras <- max(terraclim_stack)
    writeRaster(terraclim_ras, "data/climate/terraclimate/vpd.tif", format = "GTiff", overwrite = TRUE)
  }
}
```

Read processed climate data.

```{r}
terraclim_ras <- raster::stack(
  "data/climate/terraclimate/tmp.tif",
  "data/climate/terraclimate/ppt.tif",
  "data/climate/terraclimate/vpd.tif"
)
names(terraclim_ras) <- c("tmp", "ppt", "vpd")
raster::proj4string(terraclim_ras) # WGS84
```

## Extract climate data at occurrence sites and then compare

Use GBIF occurrence data longitude and latitude to extract site climate values from CHELSA and PRISM rasters.

```{r, eval=FALSE}
gbif_sf_wgs84 <- read_rds(gbif_file) %>%
  mutate(
    species = consolidatedName,
    key = as.character(key)
  ) %>%
  dplyr::select(key, species, longitude, latitude) %>%
  st_as_sf(
    coords = c("longitude", "latitude"),
    crs = "+proj=longlat +datum=WGS84 +no_defs"
  )

gbif_sf_nad83 <- gbif_sf_wgs84 %>%
  st_transform(crs = "+proj=longlat +datum=NAD83 +no_defs")

chelsa_gbif_sf <- chelsa_ras %>%
  raster::extract(gbif_sf_wgs84) %>%
  as_tibble() %>%
  rename_with(~ str_c("chelsa_", .)) %>%
  bind_cols(gbif_sf_wgs84)

prism_gbif_sf <- prism_ras %>%
  raster::extract(gbif_sf_nad83) %>%
  as_tibble() %>%
  mutate(vpd = vpd * 100) %>% # prism vpd * 100 = chelsa vpd unit
  rename_with(~ str_c("prism_", .)) %>%
  bind_cols(gbif_sf_nad83)

terraclim_gbif_sf <- terraclim_ras %>%
  raster::extract(gbif_sf_wgs84) %>%
  as_tibble() %>%
  mutate(vpd = vpd * 1000) %>% # terraclim vpd * 1000 = chelsa vpd unit
  rename_with(~ str_c("terraclim_", .)) %>%
  bind_cols(gbif_sf_wgs84)

bind_cols(
  chelsa_gbif_sf %>%
    dplyr::select(geometry, key, species, starts_with("chelsa_")),
  prism_gbif_sf %>%
    dplyr::select(starts_with("prism_")),
  terraclim_gbif_sf %>%
    dplyr::select(starts_with("terraclim_"))
) %>%
  write_rds("data/climate/climate-gbif-2022-09-18.rds")
```

Pointer to file name.

```{r}
clim_file <- "data/climate/climate-gbif-2022-09-18.rds"
```

Compare CHELSA, PRISM, and TerraClimate data at GBIF occurrence locations, by making scatter plots with correlation. 

```{r}
clim_gbif_tbl <- read_rds(clim_file) %>%
  as_tibble() %>%
  drop_na() # PRISM = NA in Mexico

clim_gbif_tbl_compare <- bind_rows(
  clim_gbif_tbl %>%
    dplyr::select(
      tmp1 = chelsa_tmp,
      tmp2 = prism_tmp,
      ppt1 = chelsa_ppt,
      ppt2 = prism_ppt,
      vpd1 = chelsa_vpd,
      vpd2 = prism_vpd
    ) %>%
    mutate(compare = "chelsa-prism"),
  clim_gbif_tbl %>%
    dplyr::select(
      tmp1 = chelsa_tmp,
      tmp2 = terraclim_tmp,
      ppt1 = chelsa_ppt,
      ppt2 = terraclim_ppt,
      vpd1 = chelsa_vpd,
      vpd2 = terraclim_vpd
    ) %>%
    mutate(compare = "chelsa-terraclim"),
  clim_gbif_tbl %>%
    dplyr::select(
      tmp1 = prism_tmp,
      tmp2 = terraclim_tmp,
      ppt1 = prism_ppt,
      ppt2 = terraclim_ppt,
      vpd1 = prism_vpd,
      vpd2 = terraclim_vpd
    ) %>%
    mutate(compare = "prism-terraclim")
)

ggplot(clim_gbif_tbl_compare, aes(tmp1, tmp2)) +
  geom_hex(bins = 100) +
  viridis::scale_fill_viridis() +
  geom_smooth(method = "lm", formula = y ~ x, se = FALSE, color = "red", lty = "dashed") +
  ggpubr::stat_cor(
    aes(label = paste(..r.label.., ..p.label.., sep = "~`,`~")),
    p.accuracy = 0.05,
    color = "red"
  ) +
  geom_abline(slope = 1, intercept = 0, color = "red") +
  coord_fixed() +
  labs(
    x = "Temperature 1 (°C)",
    y = "Temperature 2 (°C)",
    fill = "Occurrence site"
  ) +
  facet_wrap(. ~ compare)

ggplot(clim_gbif_tbl_compare, aes(ppt1, ppt2)) +
  geom_hex(bins = 100) +
  viridis::scale_fill_viridis() +
  geom_smooth(method = "lm", formula = y ~ x, se = FALSE, color = "red", lty = "dashed") +
  ggpubr::stat_cor(
    aes(label = paste(..r.label.., ..p.label.., sep = "~`,`~")),
    p.accuracy = 0.05,
    color = "red"
  ) +
  geom_abline(slope = 1, intercept = 0, color = "red") +
  coord_fixed() +
  labs(
    x = "Precipitation 1 (mm)",
    y = "Precipitation 2 (mm)",
    fill = "Occurrence site"
  ) +
  facet_wrap(. ~ compare)

ggplot(clim_gbif_tbl_compare, aes(vpd1, vpd2)) +
  geom_hex(bins = 100) +
  viridis::scale_fill_viridis() +
  geom_smooth(method = "lm", formula = y ~ x, se = FALSE, color = "red", lty = "dashed") +
  ggpubr::stat_cor(
    aes(label = paste(..r.label.., ..p.label.., sep = "~`,`~")),
    p.accuracy = 0.05,
    color = "red"
  ) +
  geom_abline(slope = 1, intercept = 0, color = "red") +
  coord_fixed() +
  labs(
    x = "VPD max 1 (Pa)",
    y = "VPD max 2 (Pa)",
    fill = "Occurrence site"
  ) +
  facet_wrap(. ~ compare)
```

Making maps is possible but too time consuming.

```{r, eval=FALSE}
clim_long_sf <- read_rds(clim_file) %>%
  pivot_longer(
    contains(match = c("chelsa", "prism")),
    names_to = "dataset_variable",
    values_to = "value"
  ) %>%
  separate(
    col = dataset_variable,
    into = c("dataset", "variable"),
    sep = "_"
  )

ggplot() +
  geom_sf(
    data = rnaturalearth::ne_states(
      country = c("Mexico", "United States of America"),
      returnclass = "sf"
    ),
    fill = NA,
    color = alpha("black", .1)
  ) +
  geom_sf(data = cfp_sf, fill = "white", alpha = .5) +
  geom_sf(
    data = clim_long_sf,
    aes(geometry = geometry, color = value),
    alpha = .1, size = .1
  ) +
  facet_wrap(variable ~ dataset) +
  scale_color_viridis() +
  labs(x = "Longitude", y = "Latitude") +
  coord_sf(xlim = c(-125, -115), ylim = c(28, 44))
```

Remove intermediate objects.

```{r}
rm(chelsa_ras, prism_ras, terraclim_ras)
rm(clim_gbif_tbl, clim_gbif_tbl_compare)
```

# Quantify species climate niches

## Individual species

Visualize individual species occurrence in climate space.

```{r, eval=FALSE}
# read combined GBIF and CHELSA data
gbif_chelsa_sf <- read_rds(clim_file) %>%
  select(geometry, key, species, tmp = chelsa_tmp, ppt = chelsa_ppt, vpd = chelsa_vpd) %>%
  st_as_sf(crs = "+proj=longlat +datum=WGS84 +no_defs")

# check species lists
sp_gbif_vec <- gbif_chelsa_sf %>%
  pull(species) %>%
  unique() %>%
  sort()
sp_comm_vec <- spp_tbl %>%
  mutate(final_name = ifelse(
    is.na(consolidated_name),
    query_name,
    consolidated_name
  )) %>%
  pull(final_name) %>%
  unique() %>%
  sort()
sp_gbif_vec %in% sp_comm_vec

# gbif summary
tmp_rng <- range(gbif_chelsa_sf$tmp)
ppt_rng <- range(gbif_chelsa_sf$ppt)
n_occ_tot <- nrow(gbif_chelsa_sf)
# exp data summary
exp_tbl <- read_rds("data/community/all-experimental-data.rds")
n_exp_tot <- nrow(exp_tbl)
# obs data summary
obs_tbl <- read_rds("data/community/all-observational-data.rds")
n_obs_tot <- nrow(obs_tbl)
niche_gg <- vector(mode = "list")

for (i in seq_along(sp_gbif_vec)) {
  sp <- sp_gbif_vec[i]
  occ_sp_sf <- filter(gbif_chelsa_sf, species == sp)

  occ_sp_stat <- occ_sp_sf %>%
    as_tibble() %>%
    summarise(
      occ_n = n(),
      tmp_occ_mean = mean(tmp, na.rm = TRUE),
      tmp_occ_sd = sd(tmp, na.rm = TRUE),
      ppt_occ_mean = mean(ppt, na.rm = TRUE),
      ppt_occ_sd = sd(ppt, na.rm = TRUE)
    )
  n_exp_sp <- exp_tbl %>%
    filter(species == sp) %>%
    nrow()
  n_obs_sp <- obs_tbl %>%
    filter(species == sp) %>%
    nrow()

  occ_geog <- ggplot() +
    geom_sf(
      data = rnaturalearth::ne_states(
        country = c("Mexico", "United States of America"),
        returnclass = "sf"
      ),
      fill = NA,
      color = alpha("black", .1)
    ) +
    geom_sf(data = cfp_sf, fill = "white", alpha = .5) +
    geom_sf(data = occ_sp_sf, alpha = .1, size = .5) +
    labs(x = "Longitude", y = "Latitude", title = sp) +
    coord_sf(xlim = c(-125, -115), ylim = c(28, 44)) +
    theme(plot.title = element_text(face = "italic"))

  occ_clim <- ggplot(occ_sp_sf, aes(tmp, ppt)) +
    geom_point(alpha = .5, size = .5) +
    geom_rug(alpha = .5) +
    stat_ellipse(col = "red") +
    geom_point(
      data = occ_sp_stat,
      aes(x = tmp_occ_mean, y = ppt_occ_mean),
      shape = 3, col = "red", size = 10
    ) +
    lims(x = tmp_rng, y = ppt_rng) +
    # scale_y_log10() + # log scale ppt
    labs(
      x = "Mean annual temperature (°C)", y = "Annual precipitation (mm)",
      title = str_c(
        "n_occ = ", occ_sp_stat$occ_n, " (", round(occ_sp_stat$occ_n / n_occ_tot * 100, digits = 3), "%)\n",
        "n_exp = ", n_exp_sp, " (", round(n_exp_sp / n_exp_tot * 100, digits = 3), "%)\n",
        "n_obs = ", n_obs_sp, " (", round(n_obs_sp / n_obs_tot * 100, digits = 3), "%)"
      )
    )

  print(sp)
  niche_gg[[i]] <- occ_geog + occ_clim # no need to print(); will slow down
}

names(niche_gg) <- sp_gbif_vec
```

Print all species into a multi-page PDF.

```{r, eval=FALSE}
# runtime ~= 4 min
pdf("figures/species-climate-niche-2022-09-18.pdf", width = 8, height = 8 * .618)
print(niche_gg)
dev.off()
```

## All species

Summarize species climate niches (mean, sd, etc.).

```{r}
niche_tbl <- read_rds(clim_file) %>%
  select(key, species, tmp = chelsa_tmp, ppt = chelsa_ppt, vpd = chelsa_vpd) %>%
  group_by(species) %>%
  summarize(
    occ_n = n(),
    tmp_occ_mean = mean(tmp, na.rm = TRUE),
    tmp_occ_sd = sd(tmp, na.rm = TRUE),
    tmp_occ_median = median(tmp, na.rm = TRUE),
    tmp_occ_q05 = quantile(tmp, .05, na.rm = TRUE),
    tmp_occ_q25 = quantile(tmp, .25, na.rm = TRUE),
    tmp_occ_q75 = quantile(tmp, .75, na.rm = TRUE),
    tmp_occ_q95 = quantile(tmp, .95, na.rm = TRUE), # hot limit, suggested by Susan Harrison
    ppt_occ_mean = mean(ppt, na.rm = TRUE),
    ppt_occ_sd = sd(ppt, na.rm = TRUE),
    ppt_occ_median = median(ppt, na.rm = TRUE),
    ppt_occ_q05 = quantile(ppt, .05, na.rm = TRUE), # dry limit, suggested by Susan Harrison
    ppt_occ_q25 = quantile(ppt, .25, na.rm = TRUE),
    ppt_occ_q75 = quantile(ppt, .75, na.rm = TRUE),
    ppt_occ_q95 = quantile(ppt, .95, na.rm = TRUE),
    vpd_occ_mean = mean(vpd, na.rm = TRUE),
    vpd_occ_sd = sd(vpd, na.rm = TRUE),
    vpd_occ_median = median(vpd, na.rm = TRUE),
    vpd_occ_q05 = quantile(vpd, .05, na.rm = TRUE),
    vpd_occ_q25 = quantile(vpd, .25, na.rm = TRUE),
    vpd_occ_q75 = quantile(vpd, .75, na.rm = TRUE),
    vpd_occ_q95 = quantile(vpd, .95, na.rm = TRUE)
  )
```

These different summary statistics (mean, median, upper, and lower quantiles) are highly and significantly correlated.

```{r fig.cap="Species temperature niche statistics (°C)"}
niche_tbl %>%
  select(tmp_occ_mean, tmp_occ_median, tmp_occ_q05, tmp_occ_q95) %>%
  GGally::ggpairs(
    title = "Species temperature niche (°C)",
    columnLabels = c("Mean", "Median", "Lower limit (5%)", "Upper limit (95%)"),
  )
```

```{r fig.cap="Species precipitation niche statistics (mm)"}
niche_tbl %>%
  select(ppt_occ_mean, ppt_occ_median, ppt_occ_q05, ppt_occ_q95) %>%
  GGally::ggpairs(
    title = "Species precipitation niche (mm)",
    columnLabels = c("Mean", "Median", "Lower limit (5%)", "Upper limit (95%)")
  )
```

```{r fig.cap="Species VPD max niche statistics (Pa)"}
niche_tbl %>%
  select(vpd_occ_mean, vpd_occ_median, vpd_occ_q05, vpd_occ_q95) %>%
  GGally::ggpairs(
    title = "Species VPD max niche (Pa)",
    columnLabels = c("Mean", "Median", "Lower limit (5%)", "Upper limit (95%)")
  )
```

Different dimensions of the niche space (temperature, precipitation, and VPD max) are also correlated (using mean as summary).

```{r fig.cap="Correlation of species niche dimensions"}
niche_tbl %>%
  select(tmp_occ_median, ppt_occ_median, vpd_occ_median) %>%
  GGally::ggpairs(
    title = "Species niche dimensions",
    columnLabels = c("Temperature (°C)", "Precipitation (mm)", "VPD max (Pa)")
  )
```

With all the correlations, we can safely use temperature and precipitation to visualize species niches in climate space. Note the strong negative correlation between temperature and precipitation (r = `r format(with(niche_tbl, cor(tmp_occ_mean, ppt_occ_mean)), digits = 3)`, p = `r format(with(niche_tbl, cor.test(tmp_occ_mean, ppt_occ_mean))$p.value, digits = 3)`).

```{r fig.cap="Species climate niches, with mean (point) and standard error (crossbar)"}
niche_tbl %>%
  ggplot(aes(
    text = species,
    x = tmp_occ_mean,
    y = ppt_occ_mean,
    xmin = tmp_occ_mean - tmp_occ_sd / sqrt(occ_n),
    xmax = tmp_occ_mean + tmp_occ_sd / sqrt(occ_n),
    ymin = ppt_occ_mean - ppt_occ_sd / sqrt(occ_n),
    ymax = ppt_occ_mean + ppt_occ_sd / sqrt(occ_n)
  )) +
  geom_point() +
  geom_errorbarh(alpha = .5) +
  geom_errorbar(alpha = .5) +
  labs(
    x = "Species occurrence mean temperature (°C)",
    y = "Species occurrence mean precipitation (mm)"
  )
```

```{r fig.cap="Interactive figure, no error bars"}
(niche_tbl %>%
  ggplot(aes(
    text = species,
    x = tmp_occ_mean,
    y = ppt_occ_mean,
  )) +
  geom_point() +
  labs(
    x = "Species occurrence mean temperature (°C)",
    y = "Species occurrence mean precipitation (mm)"
  )
) %>%
  plotly::ggplotly(tooltip = "text")
```

This figure compares well with Josie's estimates. 

```{r, fig.cap="Species climate niches (mean and standard error) estimated by Josie"}
(read_csv("data/archives/CAGrasslandCommunityChange-master/Analysis/CTI Data/AllSite_CTI_08_2020.csv") %>%
  filter(
    species.name != "Linanthus jepsonii",
    species.name != "Linanthus latisectus",
    relcov >= 0
  ) %>%
  dplyr::select(species = species.name, guild, tmp = meanT, ppt = meanp) %>%
  distinct() %>%
  ggplot(aes(tmp, ppt, text = species)) +
  geom_point(alpha = .5) +
  # geom_smooth(method = "lm", aes(tmp, ppt)) +
  labs(
    x = "Species occurrence mean temperature (°C)",
    y = "Species occurrence mean precipitation (mm)"
  )
) %>%
  plotly::ggplotly(tooltip = "text")
```

Prepare to save niche estimates.

```{r}
niche_tbl <- niche_tbl %>%
  select(
    species, occ_n,
    tmp_occ_mean, tmp_occ_sd,
    tmp_occ_median, tmp_occ_q05, tmp_occ_q25, tmp_occ_q75, tmp_occ_q95,
    ppt_occ_mean, ppt_occ_sd,
    ppt_occ_median, ppt_occ_q05, ppt_occ_q25, ppt_occ_q75, ppt_occ_q95,
    vpd_occ_mean, vpd_occ_sd,
    vpd_occ_median, vpd_occ_q05, vpd_occ_q25, vpd_occ_q75, vpd_occ_q95
  )
```

Create dummy species, append to niche estimates, and save.

```{r}
Avena_tbl <- niche_tbl %>%
  filter(species %in% c(
    "Avena barbata",
    "Avena fatua"
  )) %>%
  summarize(across(-c(species:occ_n), mean))

Festuca_tbl <- niche_tbl %>%
  filter(species %in% c(
    "Festuca bromoides",
    "Festuca perennis"
  )) %>%
  summarize(across(-c(species:occ_n), mean))

Hypochaeris_tbl <- niche_tbl %>%
  filter(species %in% c(
    "Hypochaeris glabra",
    "Hypochaeris radicata"
  )) %>%
  summarize(across(-c(species:occ_n), mean))

Raphanus_tbl <- niche_tbl %>%
  filter(species %in% c(
    "Raphanus sativus",
    "Raphanus raphanistrum" # this species doesn't exist from GBIF download
  )) %>%
  summarize(across(-c(species:occ_n), mean))

niche_tbl %>%
  add_row(species = "Avena DUMMY", occ_n = NA, Avena_tbl) %>%
  add_row(species = "Festuca DUMMY", occ_n = NA, Festuca_tbl) %>%
  add_row(species = "Hypochaeris DUMMY", occ_n = NA, Hypochaeris_tbl) %>%
  add_row(species = "Raphanus DUMMY", occ_n = NA, Raphanus_tbl) %>%
  write_rds("data/occurrence/niche-estimates-cfp-2022-09-18.rds")
```

Remove intermediate objects.

```{r}
rm(Avena_tbl, Festuca_tbl, Hypochaeris_tbl, niche_tbl, Raphanus_tbl)
rm(cfp_sf, spp_tbl)
rm(clim_file, gbif_file)
```

## Spatial thinning occurrence records

Spatial thinning GBIF-CHELSA data to validate climate niche estimates, using the **spThin** package.

Reference:
Aiello-Lammens, Matthew E., Robert A. Boria, Aleksandar Radosavljevic, Bruno Vilela, and Robert P. Anderson. “SpThin: An R Package for Spatial Thinning of Species Occurrence Records for Use in Ecological Niche Models.” Ecography 38, no. 5 (2015): 541–45. https://doi.org/10.1111/ecog.01132.

```{r, eval=FALSE}
# run time = 22 min
occ_clim_sf <- read_rds(clim_file) %>%
  sf::st_as_sf()

occ_clim_tbl <- sf::st_coordinates(occ_clim_sf) %>%
  as_tibble() %>%
  bind_cols(occ_clim_sf) %>%
  select(lat = Y, lon = X, key, species, tmp = chelsa_tmp, ppt = chelsa_ppt)

# species climate summary for full dataset
sp_sum_tbl <- occ_clim_tbl %>%
  group_by(species) %>%
  summarize(
    tmp_mean_full = mean(tmp), ppt_mean_full = mean(ppt),
    tmp_median_full = median(tmp), ppt_median_full = median(ppt)
  ) %>%
  arrange(species)

sp_thin_tbl <- tibble()

set.seed(31416)

for (i in seq_along(sp_sum_tbl$species)) {
  # subset species
  sp <- sp_sum_tbl$species[i]
  print(sp)
  loc_full_tbl <- occ_clim_tbl %>%
    filter(species == sp)

  # thin data
  loc_thin_ls <- spThin::thin(
    loc.data = loc_full_tbl,
    lat.col = "lat",
    long.col = "lon",
    spec.col = "species",
    thin.par = 10, # distance in km that records to be separated by
    reps = 1,
    locs.thinned.list.return = TRUE,
    write.files = FALSE,
    write.log.file = FALSE
  )

  # summarize climate
  sp_thin_tbl <- loc_full_tbl[row.names(loc_thin_ls[[1]]), ] %>%
    summarize(
      tmp_mean_thin = mean(tmp), ppt_mean_thin = mean(ppt),
      tmp_median_thin = median(tmp), ppt_median_thin = median(ppt)
    ) %>%
    bind_cols(species = sp, .) %>%
    bind_rows(sp_thin_tbl, .)
}

sp_sum_tbl %>%
  full_join(sp_thin_tbl, by = "species") %>%
  write_rds("data/occurrence/niche-estimates-cfp-2022-09-18-thin.rds")

rm(loc_full_tbl, loc_thin_ls, occ_clim_sf, occ_clim_tbl, sp_sum_tbl, sp_thin_tbl)
rm(clim_file, i, sp)
```

Post-thinning analysis.

```{r}
thin_file <- "data/occurrence/niche-estimates-cfp-2022-09-18-thin.rds"
thin_tbl <- read_rds(thin_file)
```

The comparison shows full vs. thinned niche estimates are very similar.

```{r fig.cap="Species temperature niche statistics (°C)"}
thin_tbl %>%
  select(
    tmp_mean_full, tmp_mean_thin,
    tmp_median_full, tmp_median_thin
  ) %>%
  GGally::ggpairs(
    title = "Species temperature niche (°C)",
    columnLabels = c("Full mean", "Thinned mean", "Full median", "Thinned median")
  )
```

```{r fig.cap="Species precipitation niche statistics (mm)"}
thin_tbl %>%
  select(
    ppt_mean_full, ppt_mean_thin,
    ppt_median_full, ppt_median_thin
  ) %>%
  GGally::ggpairs(
    title = "Species precipitation niche (mm)",
    columnLabels = c("Full mean", "Thinned mean", "Full median", "Thinned median")
  )
```

```{r}
rm(thin_file, thin_tbl)
```
